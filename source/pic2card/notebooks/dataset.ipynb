{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelmg to COCO format\n",
    "\n",
    "Labelmg by default creates files in the **Pascal VOC** format. Most of the latest pipelines are\n",
    "expecting the labels in COCO format.\n",
    "\n",
    "1. Pascal VOC format -> coordinates are represented as `(left_top, right_bottom)`\n",
    "2. Labelmg tool produces Pascal voc format.\n",
    "3. COCO expects all the file names should be in number format\n",
    "4. COCO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/haridas/projects/mystique/data/pic2card_dataset_nov_6/train/\"\n",
    "test_dir = \"/home/haridas/projects/mystique/data/pic2card_dataset_nov_6/val/\"\n",
    "template_test = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/templates_test_data_coco/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(f\"{template_test}/1.xml\")\n",
    "root = tree.getroot()\n",
    "fn_child = root.find(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_child.text = \"1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ET.tostring(root).decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamefn_to_intfn(data_dir, start=1000):\n",
    "    \"\"\"\n",
    "    @param data_dir: Pascal VOC format generated by labelmg.\n",
    "    @param start: File name start point.\n",
    "    \"\"\"\n",
    "    get_fn = lambda x: \".\".join(x.split(\".\")[:-1])\n",
    "\n",
    "    pp = Path(data_dir)\n",
    "    for fn in glob.glob(f\"{data_dir}/*.xml\"):\n",
    "        p = Path(fn)\n",
    "        root = ET.parse(fn).getroot()\n",
    "        fn_child = root.find(\"filename\")\n",
    "        path_child = root.find(\"path\")\n",
    "        img_fn = fn_child.text\n",
    "        \n",
    "        if not get_fn(p.name).isdigit():\n",
    "            bname = \".\".join(p.name.split(\".\")[:-1])\n",
    "            png = Path(pp / f\"{img_fn}\")\n",
    "            assert png.exists()\n",
    "            \n",
    "            imgfn_split = img_fn.split(\".\")\n",
    "            img, img_ext = \".\".join(imgfn_split[:-1]), imgfn_split[-1]\n",
    "            \n",
    "            p.rename(pp / f\"{start}.xml\")\n",
    "            png.rename(pp / f\"{start}.{img_ext}\")\n",
    "            \n",
    "            # Update the filename reference in new xml \n",
    "            fn_child.text = f\"{start}.{img_ext}\"\n",
    "            path_child.text = f\"{pp/str(start)}.{img_ext}\"\n",
    "            \n",
    "            with open(pp/f\"{start}.xml\", 'w') as f:\n",
    "                f.write(ET.tostring(root).decode(\"utf8\"))\n",
    "            \n",
    "            start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamefn_to_intfn(template_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse(\"/home/haridas/projects/mystique/data/train/1.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root.findall(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Analysis\n",
    "\n",
    "Ensure the Dataset has correct labels and category ID mapping across train/val/test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_dir = \"/home/haridas/projects/mystique/data/pic2card_dataset_03_mar_2021/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann_file = \"/home/haridas/projects/mystique/data/pic2card_dataset_01_apr_2021/train_coco.json\"\n",
    "val_ann_file = \"/home/haridas/projects/mystique/data/pic2card_dataset_01_apr_2021/val_coco.json\"\n",
    "test_ann_file = \"/home/haridas/projects/mystique/data/pic2card_dataset_01_apr_2021/test_coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_aspect_ratio(bbox):\n",
    "    \"coco bbox convention\"\n",
    "    x1, y1, width, height = bbox\n",
    "    return width / height\n",
    "\n",
    "\n",
    "def get_bbox_annotations(ann_file):\n",
    "    ann = json.loads(open(ann_file).read())\n",
    "    bbox_areas = pd.DataFrame.from_records([i for i in ann['annotations']])\n",
    "    bbox_areas['bbox_height'] = bbox_areas.bbox.apply(lambda x: x[3])\n",
    "    bbox_areas['bbox_width'] = bbox_areas.bbox.apply(lambda x: x[2])\n",
    "    bbox_areas['aspect_ratio'] = bbox_areas.bbox.apply(bbox_aspect_ratio)\n",
    "    return bbox_areas\n",
    "\n",
    "def image_meta(ann_file):\n",
    "    ann = json.loads(open(ann_file).read())\n",
    "    image_df = pd.DataFrame.from_records([i for i in ann['images']])\n",
    "    return image_df\n",
    "\n",
    "def verify_xml_vs_coco(voc_dir, coco_json_file):\n",
    "    \"\"\"\n",
    "    Double check each annotations are being encoded\n",
    "    correctly to the coco_json format.\n",
    "    \"\"\"\n",
    "    ann_df = get_bbox_annotations(coco_json_file)\n",
    "    ann_count_dict = dict(ann_df.groupby(\"image_id\").count()['area'].items()) \n",
    "    #return ann_count_dict, ann_df\n",
    "    for xfile in glob.glob(f\"{voc_dir}/*.xml\"):\n",
    "        root = ET.parse(xfile)\n",
    "        obj_count = len(root.findall(\"object\"))\n",
    "        img_id = xfile.split(\"/\")[-1].split('.')[0]\n",
    "        assert(obj_count == ann_count_dict[int(img_id)]), f\"{obj_count} == {ann_count_dict[int(img_id)]}, {xfile} -> {img_id}\"\n",
    "        #raise Exception(\"Annotation mismatch between coco object and voc\")\n",
    "    print(f\"All bbox count matched for: {voc_dir} and {coco_json_file}\")\n",
    "    \n",
    "train_annotations = get_bbox_annotations(train_ann_file)\n",
    "val_annotations = get_bbox_annotations(val_ann_file)\n",
    "test_annotations = get_bbox_annotations(test_ann_file)\n",
    "train_image_df = image_meta(train_ann_file)\n",
    "test_image_df = image_meta(test_ann_file)\n",
    "val_image_df = image_meta(val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_xml_vs_coco(\"/home/haridas/projects/mystique/data/pic2card_dataset_01_apr_2021/train\", train_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image_df.describe(percentiles=np.arange(0, 1, 0.1))\n",
    "train_dict = json.loads(open(train_ann_file).read())\n",
    "val_dict = json.loads(open(val_ann_file).read())\n",
    "test_dict = json.loads(open(test_ann_file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.plot.scatter(\"bbox_width\", \"bbox_height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_annotations1 = get_bbox_annotations(train_ann_file_new)\n",
    "# train_image_df1 = image_meta(train_ann_file_new)\n",
    "# train_dict1 = json.loads(open(train_ann_file_new).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_df.id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict1.keys()\n",
    "# dict(train_annotations.groupby(\"image_id\").count()['area'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict1['annotations']\n",
    "# 546/422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations[(train_annotations.aspect_ratio > 1.29) & (train_annotations.aspect_ratio < 1.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(train_dict1[\"images\"], key=lambda x: x['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_area[bbox_area.area == 458216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.aspect_ratio.hist(bins=np.arange(0, 30, 1), xlabelsize=10, figsize=(20,10))\n",
    "# bbox_area.aspect_ratio.plot(kind=\"pie\", xticks=[0, 0.5, 0.1, 1.5], xlim=(0, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.aspect_ratio.describe(percentiles=np.arange(0, 1, 0.05))[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations[train_annotations.aspect_ratio >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_bbox.hist(column=\"area\", bins=1000)\n",
    "sorted(train_annotations[train_annotations.aspect_ratio >= 20].image_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BBOX Count distribution analysis\n",
    "bbox_count_dist = train_annotations.groupby(\"image_id\").count()[\"area\"]\n",
    "bbox_count_dist[bbox_count_dist > 35].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_count_dist.describe(np.arange(0, 1, 0.05))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with more than n bboxes. Seems overkill for an card based detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_area[bbox_area.image_id == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Category analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_category_id(ann_file):\n",
    "    ann = json.loads(open(ann_file).read())\n",
    "    cat_map = {i[\"id\"] : i[\"name\"] for i in ann[\"categories\"]}\n",
    "    print(f\"Number of images: {len(set([i['file_name'] for i in ann['images']]))}\")\n",
    "    categories = {(k, cat_map[k]): v for k, v in sorted(\n",
    "        Counter([i[\"category_id\"] for i in ann[\"annotations\"]]).items(), key=lambda x: x[0])}\n",
    "    \n",
    "    total_bboxes = sum([v for v in categories.values()])\n",
    "    \n",
    "    print(categories)\n",
    "    print({k: f\"{(v/total_bboxes) * 100:0.02f}%\" for k, v in categories.items()})\n",
    "    #return sorted(ann[\"categories\"], key=lambda x: x['id'])\n",
    "\n",
    "check_category_id(train_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_category_id(val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_category_id(test_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([i[\"category_id\"] for i in ann[\"annotations\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.groupby(\"filename\").count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morph font weight analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/tmp/pic2card.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_coord = (27.74326380342245, 58.549769282341, 284.94907945394516, 86.0945338010788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img = image.crop(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_img = np.asarray(cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(c_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bin_img = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_img = np.count_nonzero(bin_img)\n",
    "area_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_img = np.zeros(bin_img.shape, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_open = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(morph_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img =cv2.subtract(bin_img, morph_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(bin_img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(skel_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_img = cv2.bitwise_or(skel_img, tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(skel_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(image: Image, coords) -> str:\n",
    "        \"\"\"\n",
    "        Extract the weight of the each words by\n",
    "        skeletization applying morph operations on\n",
    "        the input image\n",
    "        @param image : input PIL image\n",
    "        @param coords: list of coordinated from which\n",
    "                       text and height should be extracted\n",
    "        @return: weight\n",
    "        \"\"\"\n",
    "        cropped_image = image.crop(coords)\n",
    "        c_img = np.asarray(cropped_image)\n",
    "        \"\"\"\n",
    "        if(image_height/image_width) < 1:\n",
    "            y_scale = round((800/image_width), 2)\n",
    "            x_scale = round((500/image_height), 2)\n",
    "            c_img = cv2.resize(c_img, (0, 0), fx=x_scale, fy=y_scale)\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(c_img, cv2.COLOR_BGR2GRAY)\n",
    "        # Converting input image to binary format\n",
    "        _, img = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "        area_of_img = np.count_nonzero(img)\n",
    "        # creating an empty skeleton\n",
    "        skel = np.zeros(img.shape, np.uint8)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "        # Loop until erosion leads to thinning text in image to singular pixel\n",
    "        images = []\n",
    "        images.append(Image.fromarray(img))\n",
    "        while True:\n",
    "            morph_open = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "            temp = cv2.subtract(img, morph_open)\n",
    "            eroded = cv2.erode(img, kernel)\n",
    "            skel = cv2.bitwise_or(skel, temp)\n",
    "            img = eroded.copy()\n",
    "            \n",
    "            images.append(Image.fromarray(skel))\n",
    "            # if no white pixels left the image has been completely eroded\n",
    "            if cv2.countNonZero(img) == 0:\n",
    "                break\n",
    "        # length of the lines in text\n",
    "        area_of_skel = np.sum(skel)/255\n",
    "        # width of line = area of the line / length of the line\n",
    "        thickness = round(area_of_img/area_of_skel, 2)\n",
    "        return thickness, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think, inter_images = get_weight(image, bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(inter_images[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_img = np.asarray(inter_images[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(proc_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_img[proc_img.nonzero()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
