{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow import keras\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from mystique.initial_setups import set_graph_and_tensors\n",
    "from mystique.predict_card import PredictCard\n",
    "from mystique.obj_detect.tf2_frcnn import Tf2ObjectDetection\n",
    "from mystique.utils import plot_results\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen_graph from saved_model\n",
    "\n",
    "Using the tf2 object detection tools convert the checkpoint (The one works well) to a saved_model format.\n",
    "\n",
    "from this saved_model format, using the below method convert it into a single frozen_graph for easy packaging with application in case of pic2card. There is no dedicated tools available to do this process in tf2 version as it got\n",
    "depricated in tf2 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = tf.compat.v1.GraphDef()\n",
    "imported = tf.saved_model.load(\n",
    "    \"/home/haridas/projects/AdaptiveCards/source/pic2card/out/faster-rcnn-resnet152_new_data-1616667991/exported/saved_model/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_fun = imported.signatures['serving_default']\n",
    "frozen_func = convert_variables_to_constants_v2(concrete_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_variables_to_constants_v2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen_func.graph.as_graph_def?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"/home/haridas/projects/AdaptiveCards/source/pic2card/out/faster-rcnn-resnet152_new_data-1616667991/exported/\",\n",
    "                  name=\"frozen_graph.pb\",\n",
    "                  as_text=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nodes = [i.name for i in frozen_func.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = frozen_func.graph.get_operations()\n",
    "output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inspection snippets from https://gist.github.com/lukmanr/\n",
    "\n",
    "def describe_graph(graph_def, show_nodes=False):\n",
    "    print('Input Feature Nodes: {}'.format(\n",
    "      [node.name for node in graph_def.node if node.op=='Placeholder']))\n",
    "    print('')\n",
    "    print('Unused Nodes: {}'.format(\n",
    "      [node.name for node in graph_def.node if 'unused'  in node.name]))\n",
    "    print('')\n",
    "    print('Output Nodes: {}'.format( \n",
    "      [node.name for node in graph_def.node if (\n",
    "          'predictions' in node.name or 'softmax' in node.name)]))\n",
    "    print('')\n",
    "    print('Quantization Nodes: {}'.format(\n",
    "      [node.name for node in graph_def.node if 'quant' in node.name]))\n",
    "    print('')\n",
    "    print('Constant Count: {}'.format(\n",
    "      len([node for node in graph_def.node if node.op=='Const'])))\n",
    "    print('')\n",
    "    print('Variable Count: {}'.format(\n",
    "      len([node for node in graph_def.node if 'Variable' in node.op])))\n",
    "    print('')\n",
    "    print('Identity Count: {}'.format(\n",
    "      len([node for node in graph_def.node if node.op=='Identity'])))\n",
    "    print('', 'Total nodes: {}'.format(len(graph_def.node)), '')\n",
    "\n",
    "    if show_nodes==True:\n",
    "        for node in graph_def.node:\n",
    "            print('Op:{} - Name: {}'.format(node.op, node.name))\n",
    "            \n",
    "            \n",
    "def get_size(model_dir, model_file='saved_model.pb'):\n",
    "  model_file_path = os.path.join(model_dir, model_file)\n",
    "  print(model_file_path, '')\n",
    "  pb_size = os.path.getsize(model_file_path)\n",
    "  variables_size = 0\n",
    "  if os.path.exists(\n",
    "      os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
    "    variables_size = os.path.getsize(os.path.join(\n",
    "        model_dir,'variables/variables.data-00000-of-00001'))\n",
    "    variables_size += os.path.getsize(os.path.join(\n",
    "        model_dir,'variables/variables.index'))\n",
    "  print('Model size: {} KB'.format(round(pb_size/(1024.0),3)))\n",
    "  print('Variables size: {} KB'.format(round( variables_size/(1024.0),3)))\n",
    "  print('Total Size: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size(\"/home/haridas/projects/AdaptiveCards/source/pic2card/out/faster-rcnn-resnet152_new_data-1617865643/exported/saved_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_graph(graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_graph = \"/home/haridas/projects/opensource/tf-models/research/object_detection/pic2card_model/frozen_graph.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
    "    def _imports_graph_def():\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
    "    import_graph = wrapped_import.graph\n",
    "    \n",
    "#     if print_graph == True:\n",
    "#         print(\"-\" * 50)\n",
    "#         print(\"Frozen model layers: \")\n",
    "#         layers = [op.name for op in import_graph.get_operations()]\n",
    "#         for layer in layers:\n",
    "#             print(layer)\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "    return wrapped_import.prune(\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(frozen_graph, 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    loaded = graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func = wrap_frozen_graph(graph_def=graph_def,\n",
    "                                inputs=[\"input_tensor:0\"],\n",
    "                                outputs=[\"Identity_1:0\", \"Identity_2:0\", \"Identity_4:0\"]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.name for i in frozen_func.graph.get_operations()[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/3.png\"\n",
    "img = Image.open(img_path)\n",
    "img_np = np.asarray(img)\n",
    "img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.datasets.fashion_mnist.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(tf.constant(img_np), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes, labels, scores = frozen_func(input_tensor=tf.expand_dims(tf.constant(img_np), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_outputs[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bbox(img_path) -> np.array:\n",
    "    \"\"\"\n",
    "    Predict the bounding boxes, class label and draw the bbox\n",
    "    on the original image.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img_np = np.asarray(img)\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    #img_np_copy = img_np.copy()\n",
    "    #object_detection = ObjectDetection()\n",
    "    object_detection = Tf2ObjectDetection()\n",
    "    \n",
    "    output = object_detection.get_objects(img_np, img)\n",
    "    # google models wants ymin, xmin, ymax, xmax format.\n",
    "    # output[\"detection_boxes\"] = output[\"detection_boxes\"][:, [1, 0, 3, 2]]\n",
    "    # print(output.keys())\n",
    "    \n",
    "    _img = plot_results(img,\n",
    "                 output[\"detection_classes\"],\n",
    "                 output[\"detection_scores\"],\n",
    "                 output[\"detection_boxes\"]\n",
    "                )\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"<bs64-image-str>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(predict_bbox(io.BytesIO(base64.b64decode(payload)))).save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/3.png\"\n",
    "img_path = \"/home/haridas/projects/AdaptiveCards/source/pic2card/app/assets/samples/3.png\"\n",
    "\n",
    "Image.open(predict_bbox(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/1.png\"\n",
    "Image.open(predict_bbox(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, gconf = set_graph_and_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCNN and Family\n",
    "\n",
    "Inspect the different aspect of the RCNN family of models and debug and tune them based on the\n",
    "necessity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor box generation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/haridas/projects/AdaptiveCards/source/pic2card/out/frcnn-2020-07-05-1593958532/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = tf.train.latest_checkpoint(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
