{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deter Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path, PurePath\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/home/haridas/projects/opensource/detr\")\n",
    "sys.path.insert(0, \"../\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from mystique.utils import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "import datasets\n",
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "from datasets.coco_eval import CocoEvaluator\n",
    "from datasets.coco import make_coco_transforms\n",
    "\n",
    "from models.detr import DETR, SetCriterion, PostProcess\n",
    "from models.transformer import build_transformer\n",
    "from models.backbone import build_backbone\n",
    "from models.matcher import build_matcher\n",
    "from engine import evaluate\n",
    "\n",
    "from util.misc import collate_fn, NestedTensor\n",
    "from util.plot_utils import plot_logs, plot_precision_recall\n",
    "\n",
    "from datasets.coco import make_coco_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_transform = make_coco_transforms(\"val\")\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.Resize(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Trained model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(f\"{basedir}/detr-r50-e632da11.pth\", map_location='cpu')\n",
    "# checkpoint = torch.load(f\"{basedir}/detr-r101-dc5-a2e86def.pth\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint[\"model\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Param sets that needs to be custom learned.\n",
    "# del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "# del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "# del checkpoint[\"model\"][\"query_embed.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(checkpoint, f\"{basedir}/detr-r101-dc5-a2e86def-class-head.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    coco_path = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/\"\n",
    "    dataset_file = \"pic2card\"\n",
    "    masks = False\n",
    "    \n",
    "train_ds = datasets.custom_coco_build(\"train\", Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = super(datasets.coco.CocoDetection, train_ds).__getitem__(10)\n",
    "target = {'image_id': train_ds.ids[0], 'annotations': target}\n",
    "image, target = train_ds.prepare(image, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image, _target = datasets.transforms.RandomResize([800], max_size=1333)(image, target)\n",
    "_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand()\n",
    "# region = T.RandomCrop.get_params(image, (799, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.crop(image, *T.RandomCrop.get_params(image, (400, 300)))\n",
    "# image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.transforms.crop(image, target, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.transforms.crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.permute(1, 2, 0).numpy()\n",
    "# image.permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index are directly from the coco dataset index.\n",
    "CLASSES = {\n",
    "     0: 'background', # This one is a default class learned by model, or a catch all.\n",
    "     1: 'textbox',\n",
    "     2: 'radiobutton',\n",
    "     3: 'checkbox',\n",
    "     4: 'actionset',\n",
    "     5: 'image',\n",
    "     6: 'rating'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Coco Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultConf:\n",
    "    # Basic network\n",
    "    backbone = \"resnet50\"\n",
    "    position_embedding = \"sine\"\n",
    "    hidden_dim = 256\n",
    "    dropout = 0.1\n",
    "    nheads = 8\n",
    "    dim_feedforward = 2048\n",
    "    enc_layers = 6\n",
    "    dec_layers = 6\n",
    "    pre_norm = False\n",
    "    num_queries = 100\n",
    "    aux_loss = False\n",
    "    \n",
    "    # Force to eval model\n",
    "    lr_backbone = 0\n",
    "    masks = False\n",
    "    dilation = False\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # Loss tuning params.\n",
    "    set_cost_class = 1\n",
    "    set_cost_bbox = 5\n",
    "    set_cost_giou = 2\n",
    "    bbox_loss_coef = 5\n",
    "    giou_loss_coef = 2\n",
    "    eos_coef = 0.1\n",
    "    losses = [\"labels\", \"boxes\", \"cardinality\"]\n",
    "\n",
    "    # Configuration fitting the pic2card specific\n",
    "    # class configuration.\n",
    "    coco_path = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/\"\n",
    "    dataset_file = \"pic2card\"\n",
    "\n",
    "weight_dict = {\n",
    "    'loss_ce': 1,\n",
    "    'loss_bbox': DefaultConf.bbox_loss_coef,\n",
    "    'loss_giou': DefaultConf.giou_loss_coef\n",
    "}\n",
    "    \n",
    "backbone = build_backbone(DefaultConf)\n",
    "\n",
    "transformer_network = build_transformer(DefaultConf)\n",
    "matcher = build_matcher(DefaultConf)\n",
    "criterion = SetCriterion(num_classes=len(CLASSES),\n",
    "                         matcher=matcher,\n",
    "                         weight_dict=weight_dict,\n",
    "                         eos_coef=DefaultConf.eos_coef,\n",
    "                         losses=DefaultConf.losses\n",
    "                        )\n",
    "postprocessors = {\"bbox\": PostProcess()}\n",
    "\n",
    "dataset_test = build_dataset(image_set=\"test\", args=DefaultConf)\n",
    "sample_test = SequentialSampler(dataset_test)\n",
    "base_ds = get_coco_api_from_dataset(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basedir = Path(\"/home/haridas/projects/opensource/detr/\")\n",
    "model_path = basedir / \"outputs-2020-06-30-1593500748\" / \"checkpoint.pth\"\n",
    "state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "detr = DETR(backbone=backbone,\n",
    "            transformer=transformer_network,\n",
    "            num_queries=100, num_classes=6, aux_loss=False)\n",
    "detr.load_state_dict(state_dict[\"model\"])\n",
    "detr.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = DataLoader(dataset_test,\n",
    "                              batch_size=2,\n",
    "                              sampler=sample_test,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate_fn,\n",
    "                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for samples, targets in data_loader_test:\n",
    "#     print([i['image_id'] for i in targets])\n",
    "#     import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_stats, coco_evaluator = evaluate(\n",
    "#     detr, criterion, postprocessors,\n",
    "#     data_loader_test,\n",
    "#     base_ds,\n",
    "#     device=\"cpu\",\n",
    "#     output_dir=\"./out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detr_model(model_path, num_queries=60, num_classes=6):\n",
    "    basedir = Path(model_path)\n",
    "    model_path = basedir / \"checkpoint.pth\"\n",
    "    state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "    detr = DETR(backbone=backbone,\n",
    "                transformer=transformer_network,\n",
    "                num_queries=num_queries,\n",
    "                num_classes=num_classes, aux_loss=False)\n",
    "    detr.load_state_dict(state_dict[\"model\"])\n",
    "    detr.eval();\n",
    "    return detr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/haridas/projects/opensource/detr/best_model/checkpoint.pth\"\n",
    "_detr = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_detr['model'].get(\"transformer.encoder.layers.0.self_attn.in_proj_weight\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr = load_detr_model(\"/home/haridas/projects/opensource/detr/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = make_coco_transforms(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['pred_boxes'][-1, keep]\n",
    "img = Image.open(\"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/3.png\").convert(\"RGB\")\n",
    "img = Image.open(\"/home/haridas/projects/mystique/data/templates_test_data/1.png\").convert(\"RGB\")\n",
    "probs, boxes = detect(img, detr_trace_module, transform, threshold=0.8)\n",
    "scores = probs.max(-1).values.detach().numpy()\n",
    "classes = probs.max(-1).indices.detach().numpy()\n",
    "plot_results(img, classes, scores, boxes, label_map=CLASSES, score_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.max(-1).values.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystique.models.pth.detr.predict import detect as detect_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_, boxes_ = detect_(img, detr_trace_module, transform_, threshold=0.8)\n",
    "plot_results(img, scores_, boxes_, label_map=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting train vs eval performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_experiments = [Path(i) for i in glob.glob(\"/home/haridas/projects/opensource/detr/outputs-2020-07-07*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"/home/haridas/projects/opensource/detr/best_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_json(p / \"log.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_df.head().test_coco_eval_bbox[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(p / \"checkpoint.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict[\"model\"], p / \"checkpoint_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.load(p / 'eval.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob.glob(p / 'eval/*')\n",
    "plot_precision_recall(\n",
    "    [Path(p) for p in glob.glob(\"/home/haridas/projects/opensource/detr/best_model/eval/*.pth\")]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_experiments.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logs(detr_experiments[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript \n",
    "\n",
    "See how the model can be serialized efficiently for production purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/5.png\").convert(\"RGB\")\n",
    "# im = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np = np.asarray(img)\n",
    "im = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Jit Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_trace_module = torch.jit.trace(detr, im, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_trace_module.save(\"/home/haridas/projects/pic2card-models/pytorch/detr_trace.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_trace_module = torch.jit.load(\"/home/haridas/projects/pic2card-models/pytorch/detr_trace.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = detr_trace_module(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detr_trace_module.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "@torch.jit.script\n",
    "def an_error(x):\n",
    "    #r = torch.rand(1)\n",
    "    return x\n",
    "\n",
    "@torch.jit.script\n",
    "def foo(x, y):\n",
    "    if x.max() > y.max():\n",
    "        r = x\n",
    "    else:\n",
    "        r = y\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(foo))\n",
    "# print(torch.jit.trace(foo, (torch.ones(2,3), torch.ones(1,2))).code)\n",
    "# print(foo.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.jit.trace(foo, (torch.ones(2,3), torch.ones(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(foo.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Jit Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_tscript = torch.jit.script(detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detr_tscript.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_tscript.save(\"/home/haridas/projects/pic2card-models/pytorch/detr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detr_tscript.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !du -sh /home/haridas/projects/pic2card-models/pytorch/detr.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_tscript = torch.jit.load(\"/home/haridas/projects/pic2card-models/pytorch/detr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested_tensor = NestedTensor(im, None)\n",
    "# detr_tscript(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detr_tscript(nested_tensor)\n",
    "# print(detr_tscript.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
